<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>1 多元回归 | 07-multiple-regression.utf8.md</title>
  <meta name="description" content="">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="1 多元回归 | 07-multiple-regression.utf8.md" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 多元回归 | 07-multiple-regression.utf8.md" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#multiple-regression"><i class="fa fa-check"></i><b>1</b> 多元回归</a><ul>
<li class="chapter" data-level="" data-path=""><a href="#-packages"><i class="fa fa-check"></i>所需的 packages</a></li>
<li class="chapter" data-level="" data-path=""><a href="#datacamp"><i class="fa fa-check"></i>DataCamp</a></li>
<li class="chapter" data-level="1.1" data-path=""><a href="#model3"><i class="fa fa-check"></i><b>1.1</b> 二个数值型解释变量</a><ul>
<li class="chapter" data-level="1.1.1" data-path=""><a href="#model3EDA"><i class="fa fa-check"></i><b>1.1.1</b> 数据探索分析</a></li>
<li class="chapter" data-level="1.1.2" data-path=""><a href="#model3table"><i class="fa fa-check"></i><b>1.1.2</b> 多元回归</a></li>
<li class="chapter" data-level="1.1.3" data-path=""><a href="#model3points"><i class="fa fa-check"></i><b>1.1.3</b> 观察值,拟合值,残差</a></li>
<li class="chapter" data-level="1.1.4" data-path=""><a href="#model3residuals"><i class="fa fa-check"></i><b>1.1.4</b> 残差分析</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#model4"><i class="fa fa-check"></i><b>1.2</b> 一个数值型 和一个类别型解释变量</a><ul>
<li class="chapter" data-level="1.2.1" data-path=""><a href="#model4EDA"><i class="fa fa-check"></i><b>1.2.1</b> 数据探索分析</a></li>
<li class="chapter" data-level="1.2.2" data-path=""><a href="#model4table"><i class="fa fa-check"></i><b>1.2.2</b> 多元回归: 平行斜率模型</a></li>
<li class="chapter" data-level="1.2.3" data-path=""><a href="#model4interactiontable"><i class="fa fa-check"></i><b>1.2.3</b> 多元回归：交互模型</a></li>
<li class="chapter" data-level="1.2.4" data-path=""><a href="#model4points"><i class="fa fa-check"></i><b>1.2.4</b> 观察值,拟合值,残差</a></li>
<li class="chapter" data-level="1.2.5" data-path=""><a href="#model4residuals"><i class="fa fa-check"></i><b>1.2.5</b> 残差分</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#section-1.3"><i class="fa fa-check"></i><b>1.3</b> 其他内容</a><ul>
<li class="chapter" data-level="1.3.1" data-path=""><a href="#correlationcoefficient2"><i class="fa fa-check"></i><b>1.3.1</b> 更多相关系数的内容</a></li>
<li class="chapter" data-level="1.3.2" data-path=""><a href="#simpsonsparadox"><i class="fa fa-check"></i><b>1.3.2</b> 辛普森的悖论(Simpson’s Paradox)</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path=""><a href="#section-1.4"><i class="fa fa-check"></i><b>1.4</b> 结论</a><ul>
<li class="chapter" data-level="1.4.1" data-path=""><a href="#section-1.4.1"><i class="fa fa-check"></i><b>1.4.1</b> 本书后面的内容?</a></li>
<li class="chapter" data-level="1.4.2" data-path=""><a href="#r"><i class="fa fa-check"></i><b>1.4.2</b> R代码</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<html>
<img src='https://moderndive.com/images/logos/wide_format.png' alt="ModernDive">
</html>
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="multiple-regression" class="section level1">
<h1><span class="header-section-number">1</span> 多元回归</h1>
<p>In Chapter <a href="#regression"><strong>??</strong></a> we introduced ideas related to modeling, in particular that the fundamental premise of modeling is <em>to make explicit the relationship</em> between an outcome variable <span class="math inline">\(y\)</span> and an explanatory/predictor variable <span class="math inline">\(x\)</span>. Recall further the synonyms that we used to also denote <span class="math inline">\(y\)</span> as the dependent variable and <span class="math inline">\(x\)</span> as an independent variable or covariate.</p>
<p>There are many modeling approaches one could take, among the most well-known being linear regression, which was the focus of the last chapter. Whereas in the last chapter we focused solely on regression scenarios where there is only one explanatory/predictor variable, in this chapter, we now focus on modeling scenarios where there is more than one. This case of regression more than one explanatory variable is known as multiple regression. You can imagine when trying to model a particular outcome variable, like teaching evaluation score as in Section <a href="#model1"><strong>??</strong></a> or life expectancy as in Section <a href="#model2"><strong>??</strong></a>, it would be very useful to incorporate more than one explanatory variable.</p>
<p>Since our regression models will now consider more than one explanatory/predictor variable, the interpretation of the associated effect of any one explanatory/predictor variables must be made in conjunction with the others. For example, say we are modeling individuals’ incomes as a function of their number of years of education and their parents’ wealth. When interpreting the effect of education on income, one has to consider the effect of their parents’ wealth at the same time, as these two variables are almost certainly related. Make note of this throughout this chapter and as you work on interpreting the results of multiple regression models into the future.</p>
<div id="-packages" class="section level3 unnumbered">
<h3>所需的 packages</h3>
<p>Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). Read Section <a href="#packages"><strong>??</strong></a> for information on how to install and load R packages.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(moderndive)
<span class="kw">library</span>(ISLR)
<span class="kw">library</span>(skimr)</code></pre>
</div>
<div id="datacamp" class="section level3 unnumbered">
<h3>DataCamp</h3>
<p>The approach taken below of using more than one variable of information in models using multiple regression is identical to that taken in ModernDive co-author <a href="https://twitter.com/rudeboybert">Albert Y. Kim’s</a> DataCamp course “Modeling with Data in the Tidyverse.” If you’re interested in complementing your learning below in an interactive online environment, click on the image below to access the course. The relevant chapters are Chapter 1 “Introduction to Modeling” and Chapter 3 “Modeling with Multiple Regression”.</p>
<center>
<a target="_blank" class="page-link" href="https://www.datacamp.com/courses/modeling-with-data-in-the-tidyverse"><img src="images/datacamp_intro_to_modeling.png" alt="Drawing" style="height: 150px;"/></a>
</center>
</div>
<div id="model3" class="section level2">
<h2><span class="header-section-number">1.1</span> 二个数值型解释变量</h2>
<p>Let’s now attempt to identify factors that are associated with how much credit card debt an individual will have. The textbook <a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R</a> by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani is an intermediate-level textbook on statistical and machine learning freely available <a href="http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf">here</a>. It has an accompanying R package called <code>ISLR</code> with datasets that the authors use to demonstrate various machine learning methods. One dataset that is frequently used by the authors is the <code>Credit</code> dataset where predictions are made on the credit card balance held by <span class="math inline">\(n = 400\)</span> credit card holders. These predictions are based on information about them like income, credit limit, and education level. Note that this dataset is not based on actual individuals, it is a simulated dataset used for educational purposes.</p>
<p>Since no information was provided as to who these <span class="math inline">\(n\)</span> = 400 individuals are and how they came to be included in this dataset, it will be hard to make any scientific claims based on this data. Recall our discussion from the previous chapter that correlation does not necessarily imply causation. That being said, we’ll still use <code>Credit</code> to demonstrate multiple regression with:</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, in this case credit card balance.</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A first numerical explanatory variable <span class="math inline">\(x_1\)</span>. In this case, their credit limit.</li>
<li>A second numerical explanatory variable <span class="math inline">\(x_2\)</span>. In this case, their income (in thousands of dollars).</li>
</ol></li>
</ol>
<p>In the forthcoming Learning Checks, we’ll consider a different scenario:</p>
<ol style="list-style-type: decimal">
<li>The same numerical outcome variable <span class="math inline">\(y\)</span>: credit card balance.</li>
<li>Two new explanatory variables:
<ol style="list-style-type: decimal">
<li>A first numerical explanatory variable <span class="math inline">\(x_1\)</span>: their credit rating.</li>
<li>A second numerical explanatory variable <span class="math inline">\(x_2\)</span>: their age.</li>
</ol></li>
</ol>
<div id="model3EDA" class="section level3">
<h3><span class="header-section-number">1.1.1</span> 数据探索分析</h3>
<p>Let’s load the <code>Credit</code> data and <code>select()</code> only the needed subset of variables.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
Credit &lt;-<span class="st"> </span>Credit <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Balance, Limit, Income, Rating, Age)</code></pre>
<p>Let’s look at the raw data values both by bringing up RStudio’s spreadsheet viewer and the <code>glimpse()</code> function. Although in Table <a href="#tab:model3-data-preview">1.1</a> we only show 5 randomly selected credit card holders out of 400:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(Credit)</code></pre>
<table>
<caption><span id="tab:model3-data-preview">Table 1.1: </span>Random sample of 5 credit card holders</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
<th align="right">Rating</th>
<th align="right">Age</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>31</td>
<td align="right">863</td>
<td align="right">5666</td>
<td align="right">34.1</td>
<td align="right">413</td>
<td align="right">47</td>
</tr>
<tr class="even">
<td>119</td>
<td align="right">0</td>
<td align="right">2161</td>
<td align="right">27.0</td>
<td align="right">173</td>
<td align="right">40</td>
</tr>
<tr class="odd">
<td>180</td>
<td align="right">1237</td>
<td align="right">7499</td>
<td align="right">58.0</td>
<td align="right">560</td>
<td align="right">67</td>
</tr>
<tr class="even">
<td>137</td>
<td align="right">75</td>
<td align="right">4116</td>
<td align="right">54.7</td>
<td align="right">314</td>
<td align="right">70</td>
</tr>
<tr class="odd">
<td>114</td>
<td align="right">768</td>
<td align="right">6386</td>
<td align="right">69.3</td>
<td align="right">474</td>
<td align="right">30</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(Credit)</code></pre>
<pre><code>## Observations: 400
## Variables: 5
## $ Balance &lt;int&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 14...
## $ Limit   &lt;int&gt; 3606, 6645, 7075, 9504, 4897, 8047, 3388, 7114, 3300, ...
## $ Income  &lt;dbl&gt; 14.9, 106.0, 104.6, 148.9, 55.9, 80.2, 21.0, 71.4, 15....
## $ Rating  &lt;int&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589,...
## $ Age     &lt;int&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49...</code></pre>
<p>Let’s look at some summary statistics, again using the <code>skim()</code> function from the <code>skimr</code> package:</p>
<pre class="sourceCode r"><code class="sourceCode r">Credit <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Balance, Limit, Income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">skim</span>()</code></pre>
<pre><code>## Skim summary statistics
##  n obs: 400 
##  n variables: 3 
## 
## -- Variable type:integer --------------------------------------------------------------------------------------------------
##  variable missing complete   n    mean      sd  p0     p25    p50     p75
##   Balance       0      400 400  520.01  459.76   0   68.75  459.5  863   
##     Limit       0      400 400 4735.6  2308.2  855 3088    4622.5 5872.75
##   p100     hist
##   1999 &lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2583&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2581&gt;
##  13913 &lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2581&gt;
## 
## -- Variable type:numeric --------------------------------------------------------------------------------------------------
##  variable missing complete   n  mean    sd    p0   p25   p50   p75   p100
##    Income       0      400 400 45.22 35.24 10.35 21.01 33.12 57.47 186.63
##      hist
##  &lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2581&gt;</code></pre>
<p>We observe for example:</p>
<ol style="list-style-type: decimal">
<li>The mean and median credit card balance are $520.01 and $495.50 respectively.</li>
<li>25% of card holders had debts of $68.75 or less.</li>
<li>The mean and median credit card limit are $4735.6 and $4622.50 respectively.</li>
<li>75% of these card holders had incomes of $57,470 or less.</li>
</ol>
<p>Since our outcome variable <code>Balance</code> and the explanatory variables <code>Limit</code> and
<code>Rating</code> are numerical, we can compute the correlation coefficient between pairs
of these variables. First, we could run the <code>get_correlation()</code> command as seen
in Subsection <a href="#model1EDA"><strong>??</strong></a> twice, once for each explanatory variable:</p>
<pre class="sourceCode r"><code class="sourceCode r">Credit <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_correlation</span>(Balance <span class="op">~</span><span class="st"> </span>Limit)
Credit <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_correlation</span>(Balance <span class="op">~</span><span class="st"> </span>Income)</code></pre>
<p>Or we can simultaneously compute them by returning a <em>correlation matrix</em> in
Table <a href="#tab:model3-correlation">1.2</a>. We can read off the correlation coefficient
for any pair of variables by looking them up in the appropriate row/column combination.</p>
<pre class="sourceCode r"><code class="sourceCode r">Credit <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Balance, Limit, Income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()</code></pre>
<table>
<caption><span id="tab:model3-correlation">Table 1.2: </span>Correlations between credit card balance, credit limit, and income</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Balance</td>
<td align="right">1.000</td>
<td align="right">0.862</td>
<td align="right">0.464</td>
</tr>
<tr class="even">
<td>Limit</td>
<td align="right">0.862</td>
<td align="right">1.000</td>
<td align="right">0.792</td>
</tr>
<tr class="odd">
<td>Income</td>
<td align="right">0.464</td>
<td align="right">0.792</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<p>For example, the correlation coefficient of:</p>
<ol style="list-style-type: decimal">
<li><code>Balance</code> with itself is 1 as we would expect based on the definition of the correlation coefficient.</li>
<li><code>Balance</code> with <code>Limit</code> is 0.862. This indicates a strong positive linear relationship, which makes sense as only individuals with large credit limits can accrue large credit card balances.</li>
<li><code>Balance</code> with <code>Income</code> is 0.464. This is suggestive of another positive linear relationship, although not as strong as the relationship between <code>Balance</code> and <code>Limit</code>.</li>
<li>As an added bonus, we can read off the correlation coefficient of the two explanatory variables, <code>Limit</code> and <code>Income</code> of 0.792. In this case, we say there is a high degree of <em>collinearity</em> between these two explanatory variables.</li>
</ol>
<p>Collinearity (or multicollinearity) is a phenomenon in which one explanatory variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy. So in this case, if we knew someone’s credit card <code>Limit</code> and since <code>Limit</code> and <code>Income</code> are highly correlated, we could make a fairly accurate guess as to that person’s <code>Income</code>. Or put loosely, these two variables provided redundant information. For now let’s ignore any issues related to collinearity and press on.</p>
<p>Let’s visualize the relationship of the outcome variable with each of the two explanatory variables in two separate plots:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Credit, <span class="kw">aes</span>(<span class="dt">x =</span> Limit, <span class="dt">y =</span> Balance)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Credit limit (in $)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card balance (in $)&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Relationship between balance and credit limit&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)
  
<span class="kw">ggplot</span>(Credit, <span class="kw">aes</span>(<span class="dt">x =</span> Income, <span class="dt">y =</span> Balance)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Income (in $1000)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card balance (in $)&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Relationship between balance and income&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre>
<div class="figure"><span id="fig:2numxplot1"></span>
<img src="07-multiple-regression_files/figure-html/2numxplot1-1.png" alt="Relationship between credit card balance and credit limit/income" width="\textwidth" />
<p class="caption">
Figure 1.1: Relationship between credit card balance and credit limit/income
</p>
</div>
<p>First, there is a positive relationship between credit limit and balance, since as credit limit increases so also does credit card balance; this is to be expected given the strongly positive correlation coefficient of 0.862. In the case of income, the positive relationship doesn’t appear as strong, given the weakly positive correlation coefficient of 0.464. However the two plots in Figure <a href="#fig:2numxplot1">1.1</a> only focus on the relationship of the outcome variable with each of the explanatory variables independently. To get a sense of the <em>joint</em> relationship of all three variables simultaneously through a visualization, let’s display the data in a 3-dimensional (3D) scatterplot, where</p>
<ol style="list-style-type: decimal">
<li>The numerical outcome variable <span class="math inline">\(y\)</span> <code>Balance</code> is on the z-axis (vertical axis)</li>
<li>The two numerical explanatory variables form the “floor” axes. In this case
<ol style="list-style-type: decimal">
<li>The first numerical explanatory variable <span class="math inline">\(x_1\)</span> <code>Income</code> is on of the floor axes.</li>
<li>The second numerical explanatory variable <span class="math inline">\(x_2\)</span> <code>Limit</code> is on the other floor axis.</li>
</ol></li>
</ol>
<p>Click on the following image to open an interactive 3D scatterplot in your browser:</p>
<center>
<a target="_blank" href="https://assets.datacamp.com/production/repositories/1575/datasets/f369dc94041e88effd5ed66512978f8cdfd33801/03-01-slides-interactive_3D_scatterplot_regression_plane.html"><img src="images/credit_card_balance_3D_scatterplot.png" title="3D scatterplot" width="800"/></a>
</center>
<p>Previously in Figure <a href="#fig:numxplot4"><strong>??</strong></a>, we plotted a “best-fitting” regression line through a set of points where the numerical outcome variable <span class="math inline">\(y\)</span> was teaching <code>score</code> and a single numerical explanatory variable <span class="math inline">\(x\)</span> was <code>bty_avg</code>. What is the analogous concept when we have <em>two</em> numerical predictor variables? Instead of a best-fitting line, we now have a best-fitting <em>plane</em>, which is a 3D generalization of lines which exist in 2D. Click on the following image to open an interactive plot of the regression plane in your browser. Move the image around, zoom in, and think about how this plane generalizes the concept of a linear regression line to three dimensions.</p>
<center>
<a target="_blank" href="https://beta.rstudioconnect.com/connect/#/apps/3214/"><img src="images/credit_card_balance_regression_plane.png" title="Regression plane" width="800"/></a>
</center>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC7.1)</strong> Conduct a new exploratory data analysis with the same outcome variable <span class="math inline">\(y\)</span> being <code>Balance</code> but with <code>Rating</code> and <code>Age</code> as the new explanatory variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. Remember, this involves three things:</p>
<ol style="list-style-type: lower-alpha">
<li>Looking at the raw values</li>
<li>Computing summary statistics of the variables of interest.</li>
<li>Creating informative visualizations</li>
</ol>
<p>What can you say about the relationship between a credit card holder’s balance and their credit rating and age?</p>
<!-- CHESTER: I'm not sold on this practice and prefer to assign new variables in R like `Credit_small` instead of overwriting. I seem to remember us agreeing that re-assignment was only OK if we added more variables in Chapter 2-5, not if we chose a subset. We should stay consistent throughout so I'd recommend switching this to a different name as I have with `evals` in Chapters 6 and 7. -->
<div class="learncheck">

</div>
</div>
<div id="model3table" class="section level3">
<h3><span class="header-section-number">1.1.2</span> 多元回归</h3>
<p>Just as we did when we had a single numerical explanatory variable <span class="math inline">\(x\)</span> in Subsection <a href="#model1table"><strong>??</strong></a> and when we had a single categorical explanatory variable <span class="math inline">\(x\)</span> in Subsection <a href="#model2table"><strong>??</strong></a>, we fit a regression model and obtained the regression table in our two numerical explanatory variable scenario. To fit a regression model and get a table using <code>get_regression_table()</code>, we now use a <code>+</code> to consider multiple explanatory variables. In this case since we want to perform a regression of <code>Limit</code> and <code>Income</code> simultaneously, we input <code>Balance ~ Limit + Income</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">Balance_model &lt;-<span class="st"> </span><span class="kw">lm</span>(Balance <span class="op">~</span><span class="st"> </span>Limit <span class="op">+</span><span class="st"> </span>Income, <span class="dt">data =</span> Credit)
<span class="kw">get_regression_table</span>(Balance_model)</code></pre>
<table>
<caption><span id="tab:model3-table-output">Table 1.3: </span>Multiple regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">lower_ci</th>
<th align="right">upper_ci</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">-385.179</td>
<td align="right">19.465</td>
<td align="right">-19.8</td>
<td align="right">0</td>
<td align="right">-423.446</td>
<td align="right">-346.912</td>
</tr>
<tr class="even">
<td align="left">Limit</td>
<td align="right">0.264</td>
<td align="right">0.006</td>
<td align="right">45.0</td>
<td align="right">0</td>
<td align="right">0.253</td>
<td align="right">0.276</td>
</tr>
<tr class="odd">
<td align="left">Income</td>
<td align="right">-7.663</td>
<td align="right">0.385</td>
<td align="right">-19.9</td>
<td align="right">0</td>
<td align="right">-8.420</td>
<td align="right">-6.906</td>
</tr>
</tbody>
</table>
<p>How do we interpret these three values that define the regression plane?</p>
<ul>
<li>Intercept: -$385.18 (rounded to two decimal points to represent cents). The intercept in our case represents the credit card balance for an individual who has both a credit <code>Limit</code> of $0 and <code>Income</code> of $0. In our data however, the intercept has limited practical interpretation as no individuals had <code>Limit</code> or <code>Income</code> values of $0 and furthermore the smallest credit card balance was $0. Rather, it is used to situate the regression plane in 3D space.</li>
<li>Limit: $0.26. Now that we have multiple variables to consider, we have to add
a caveat to our interpretation: <em>taking all other variables in our model into account, for every increase of one unit in credit <code>Limit</code> (dollars), there is an associated increase of on average $0.26 in credit card balance</em>. Note:
<ul>
<li>Just as we did in Subsection <a href="#model1table"><strong>??</strong></a>, we are not making any causal statements, only statements relating to the association between credit limit and balance</li>
<li>We need to preface our interpretation of the associated effect of <code>Limit</code> with the statement “taking all other variables into account”, in this case <code>Income</code>, to emphasize that we are now jointly interpreting the associated effect of multiple explanatory variables in the same model and not in isolation.</li>
</ul></li>
<li>Income: -$7.66. Similarly, <em>taking all other variables into account, for every increase of one unit in <code>Income</code> (in other words, $1000 in income), there is an associated decrease of on average $7.66 in credit card balance</em>.</li>
</ul>
<p>However, recall in Figure <a href="#fig:2numxplot1">1.1</a> that when considered separately, both <code>Limit</code> and <code>Income</code> had positive relationships with the outcome variable <code>Balance</code>. As card holders’ credit limits increased their credit card balances tended to increase as well, and a similar relationship held for incomes and balances. In the above multiple regression, however, the slope for <code>Income</code> is now -7.66, suggesting a <em>negative relationship</em> between income and credit card balance. What explains these contradictory results?</p>
<p>This is known as Simpson’s Paradox, a phenomenon in which a trend appears in several different groups of data but disappears or reverses when these groups are combined. We expand on this in Subsection <a href="#simpsonsparadox">1.3.2</a> where we’ll look at the relationship between credit <code>Limit</code> and credit card balance but split by different income bracket groups.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC7.2)</strong> Fit a new simple linear regression using <code>lm(Balance ~ Rating + Age, data = Credit)</code> where <code>Rating</code> and <code>Age</code> are the new numerical explanatory variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. Get information about the “best-fitting” line from the regression table by applying the <code>get_regression_table()</code> function. How do the regression results match up with the results from your exploratory data analysis above?</p>
<div class="learncheck">

</div>
</div>
<div id="model3points" class="section level3">
<h3><span class="header-section-number">1.1.3</span> 观察值,拟合值,残差</h3>
<p>As we did previously in Table <a href="#tab:model3-points-table">1.4</a>, let’s unpack the output of the <code>get_regression_points()</code> function for our model for credit card balance for all 400 card holders in the dataset. Recall that each card holder corresponds to one of the 400 rows in the <code>Credit</code> data frame and also for one of the 400 3D points in the 3D scatterplots in Subsection <a href="#model3EDA">1.1.1</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(Balance_model)
regression_points</code></pre>
<table>
<caption><span id="tab:model3-points-table">Table 1.4: </span>Regression points (first 5 rows of 400)</caption>
<thead>
<tr class="header">
<th align="right">ID</th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
<th align="right">Balance_hat</th>
<th align="right">residual</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">333</td>
<td align="right">3606</td>
<td align="right">14.9</td>
<td align="right">454</td>
<td align="right">-120.8</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">903</td>
<td align="right">6645</td>
<td align="right">106.0</td>
<td align="right">559</td>
<td align="right">344.3</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">580</td>
<td align="right">7075</td>
<td align="right">104.6</td>
<td align="right">683</td>
<td align="right">-103.4</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">964</td>
<td align="right">9504</td>
<td align="right">148.9</td>
<td align="right">986</td>
<td align="right">-21.7</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">331</td>
<td align="right">4897</td>
<td align="right">55.9</td>
<td align="right">481</td>
<td align="right">-150.0</td>
</tr>
</tbody>
</table>
<p>Recall the format of the output:</p>
<ul>
<li><code>Balance</code> corresponds to <span class="math inline">\(y\)</span> (the observed value)</li>
<li><code>Balance_hat</code> corresponds to <span class="math inline">\(\widehat{y}\)</span> (the fitted value)</li>
<li><code>residual</code> corresponds to <span class="math inline">\(y - \widehat{y}\)</span> (the residual)</li>
</ul>
</div>
<div id="model3residuals" class="section level3">
<h3><span class="header-section-number">1.1.4</span> 残差分析</h3>
<p>Recall in Section <a href="#model1residuals"><strong>??</strong></a>, our first residual analysis plot investigated the presence of any systematic pattern in the residuals when we had a single numerical predictor: <code>bty_age</code>. For the <code>Credit</code> card dataset, since we have two numerical predictors, <code>Limit</code> and <code>Income</code>, we must perform this twice:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> Limit, <span class="dt">y =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Credit limit (in $)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residual&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Residuals vs credit limit&quot;</span>)
  
<span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> Income, <span class="dt">y =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Income (in $1000)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residual&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Residuals vs income&quot;</span>)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-21"></span>
<img src="07-multiple-regression_files/figure-html/unnamed-chunk-21-1.png" alt="Residuals vs credit limit and income" width="\textwidth" />
<p class="caption">
Figure 1.2: Residuals vs credit limit and income
</p>
</div>
<p>In this case, there <strong>does</strong> appear to be a systematic pattern to the residuals. As the scatter of the residuals around the line <span class="math inline">\(y=0\)</span> is definitely not consistent. This behavior of the residuals is further evidenced by the histogram of residuals in Figure <a href="#fig:model3-residuals-hist">1.3</a>. We observe that the residuals have a slight right-skew (recall we say that data is right-skewed, or positively-skewed, if there is a tail to the right). Ideally, these residuals should be bell-shaped around a residual value of 0.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Residual&quot;</span>)</code></pre>
<div class="figure"><span id="fig:model3-residuals-hist"></span>
<img src="07-multiple-regression_files/figure-html/model3-residuals-hist-1.png" alt="Relationship between credit card balance and credit limit/income" width="\textwidth" />
<p class="caption">
Figure 1.3: Relationship between credit card balance and credit limit/income
</p>
</div>
<p>Another way to interpret this histogram is that since the residual is computed as <span class="math inline">\(y - \widehat{y}\)</span> = <code>balance</code> - <code>balance_hat</code>, we have some values where the fitted value <span class="math inline">\(\widehat{y}\)</span> is very much lower than the observed value <span class="math inline">\(y\)</span>. In other words, we are underestimating certain credit card holders’ balances by a very large amount.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC7.3)</strong> Continuing with our regression using <code>Rating</code> and <code>Age</code> as the explanatory variables and credit card <code>Balance</code> as the outcome variable, use the <code>get_regression_points()</code> function to get the observed values, fitted values, and residuals for all 400 credit card holders. Perform a residual analysis and look for any systematic patterns in the residuals.</p>
<div class="learncheck">

</div>
</div>
</div>
<div id="model4" class="section level2">
<h2><span class="header-section-number">1.2</span> 一个数值型 和一个类别型解释变量</h2>
<p>Let’s revisit the instructor evaluation data introduced in Section <a href="#model1"><strong>??</strong></a>, where we studied the relationship between instructor evaluation scores and their beauty scores. This analysis suggested that there is a positive relationship between <code>bty_avg</code> and <code>score</code>, in other words as instructors had higher beauty scores, they also tended to have higher teaching evaluation scores. Now let’s say instead of <code>bty_avg</code> we are interested in the numerical explanatory variable <span class="math inline">\(x_1\)</span> <code>age</code> and furthermore we want to use a second explanatory variable <span class="math inline">\(x_2\)</span>, the (binary) categorical variable <code>gender</code>.</p>
<p><strong>Note</strong>: This study only focused on the gender binary of <code>&quot;male&quot;</code> or <code>&quot;female&quot;</code> when the data was collected and analyzed years ago. It has been tradition to use gender as an “easy” binary variable in the past in statistical analyses. We have chosen to include it here because of the interesting results of the study, but we also understand that a segment of the population is not included in this dichotomous assignment of gender and we advocate for more inclusion in future studies to show representation of groups that do not identify with the gender binary. We now resume our analyses using this <code>evals</code> data and hope that others find these results interesting and worth further exploration.</p>
<p>Our modeling scenario now becomes</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>. As before, instructor evaluation score.</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A numerical explanatory variable <span class="math inline">\(x_1\)</span>: in this case, their age.</li>
<li>A categorical explanatory variable <span class="math inline">\(x_2\)</span>: in this case, their binary gender.</li>
</ol></li>
</ol>
<div id="model4EDA" class="section level3">
<h3><span class="header-section-number">1.2.1</span> 数据探索分析</h3>
<p>Let’s reload the <code>evals</code> data and <code>select()</code> only the needed subset of variables. Note that these are different than the variables chosen in Chapter 6. Let’s given this the name <code>evals_ch7</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">evals_ch7 &lt;-<span class="st"> </span>evals <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(score, age, gender)</code></pre>
<p>Let’s look at the raw data values both by bringing up RStudio’s spreadsheet viewer and the <code>glimpse()</code> function, although in Table <a href="#tab:model4-data-preview">1.5</a> we only show 5 randomly selected instructors out of 463:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(evals_ch7)</code></pre>
<table>
<caption><span id="tab:model4-data-preview">Table 1.5: </span>Random sample of 5 instructors</caption>
<thead>
<tr class="header">
<th align="right">score</th>
<th align="right">age</th>
<th align="left">gender</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">3.6</td>
<td align="right">34</td>
<td align="left">male</td>
</tr>
<tr class="even">
<td align="right">4.9</td>
<td align="right">43</td>
<td align="left">male</td>
</tr>
<tr class="odd">
<td align="right">3.3</td>
<td align="right">47</td>
<td align="left">male</td>
</tr>
<tr class="even">
<td align="right">4.4</td>
<td align="right">33</td>
<td align="left">female</td>
</tr>
<tr class="odd">
<td align="right">4.7</td>
<td align="right">60</td>
<td align="left">male</td>
</tr>
</tbody>
</table>
<p>Let’s look at some summary statistics using the <code>skim()</code> function from the <code>skimr</code> package:</p>
<pre class="sourceCode r"><code class="sourceCode r">evals_ch7 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">skim</span>()</code></pre>
<pre><code>## Skim summary statistics
##  n obs: 463 
##  n variables: 3 
## 
## -- Variable type:factor ---------------------------------------------------------------------------------------------------
##  variable missing complete   n n_unique                top_counts ordered
##    gender       0      463 463        2 mal: 268, fem: 195, NA: 0   FALSE
## 
## -- Variable type:integer --------------------------------------------------------------------------------------------------
##  variable missing complete   n  mean  sd p0 p25 p50 p75 p100     hist
##       age       0      463 463 48.37 9.8 29  42  48  57   73 &lt;U+2585&gt;&lt;U+2585&gt;&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2582&gt;&lt;U+2581&gt;
## 
## -- Variable type:numeric --------------------------------------------------------------------------------------------------
##  variable missing complete   n mean   sd  p0 p25 p50 p75 p100     hist
##     score       0      463 463 4.17 0.54 2.3 3.8 4.3 4.6    5 &lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2582&gt;&lt;U+2583&gt;&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2587&gt;&lt;U+2586&gt;</code></pre>
<p>Furthermore, let’s compute the correlation between two numerical variables we have <code>score</code> and <code>age</code>. Recall that correlation coefficients only exist between numerical variables. We observe that they are weakly negatively correlated.</p>
<pre class="sourceCode r"><code class="sourceCode r">evals_ch7 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_correlation</span>(<span class="dt">formula =</span> score <span class="op">~</span><span class="st"> </span>age)</code></pre>
<pre><code>## # A tibble: 1 x 1
##   correlation
##         &lt;dbl&gt;
## 1      -0.107</code></pre>
<p>In Figure <a href="#fig:numxcatxplot1">1.4</a>, we plot a scatterplot of <code>score</code> over <code>age</code>. Given that <code>gender</code> is a binary categorical variable in this study, we can make some interesting tweaks:</p>
<ol style="list-style-type: decimal">
<li>We can assign a color to points from each of the two levels of <code>gender</code>: female and male.</li>
<li>Furthermore, the <code>geom_smooth(method = &quot;lm&quot;, se = FALSE)</code> layer automatically fits a different regression line for each since we have provided <code>color = gender</code> at the top level in <code>ggplot()</code>. This allows for all <code>geom_</code>etries that follow to have the same mapping of <code>aes()</code>thetics to variables throughout the plot.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(evals_ch7, <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> score, <span class="dt">color =</span> gender)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;Gender&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre>
<div class="figure"><span id="fig:numxcatxplot1"></span>
<img src="07-multiple-regression_files/figure-html/numxcatxplot1-1.png" alt="Instructor evaluation scores at UT Austin split by gender (jittered)" width="\textwidth" />
<p class="caption">
Figure 1.4: Instructor evaluation scores at UT Austin split by gender (jittered)
</p>
</div>
<p>We notice some interesting trends:</p>
<ol style="list-style-type: decimal">
<li>There are almost no women faculty over the age of 60. We can see this by the lack of red dots above 60.</li>
<li>Fitting separate regression lines for men and women, we see they have different slopes. We see that the associated effect of increasing age seems to be much harsher for women than men. In other words, as women age, the drop in their teaching score appears to be faster.</li>
</ol>
</div>
<div id="model4table" class="section level3">
<h3><span class="header-section-number">1.2.2</span> 多元回归: 平行斜率模型</h3>
<p>Much like we started to consider multiple explanatory variables using the <code>+</code> sign in Subsection <a href="#model3table">1.1.2</a>, let’s fit a regression model and get the regression table. This time we provide the name of <code>score_model_2</code> to our regression model fit, in so as to not overwrite the model <code>score_model</code> from Section <a href="#model1table"><strong>??</strong></a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">score_model_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>gender, <span class="dt">data =</span> evals_ch7)
<span class="kw">get_regression_table</span>(score_model_<span class="dv">2</span>)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-29">Table 1.6: </span>Regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">lower_ci</th>
<th align="right">upper_ci</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">4.484</td>
<td align="right">0.125</td>
<td align="right">35.79</td>
<td align="right">0.000</td>
<td align="right">4.238</td>
<td align="right">4.730</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">-0.009</td>
<td align="right">0.003</td>
<td align="right">-3.28</td>
<td align="right">0.001</td>
<td align="right">-0.014</td>
<td align="right">-0.003</td>
</tr>
<tr class="odd">
<td align="left">gendermale</td>
<td align="right">0.191</td>
<td align="right">0.052</td>
<td align="right">3.63</td>
<td align="right">0.000</td>
<td align="right">0.087</td>
<td align="right">0.294</td>
</tr>
</tbody>
</table>
<p>The modeling equation for this scenario is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{y} &amp;= b_0 + b_1 \cdot x_1 + b_2 \cdot x_2 \\
\widehat{\mbox{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x) \\
\end{align}
\]</span>
where <span class="math inline">\(\mathbb{1}_{\mbox{is male}}(x)\)</span> is an <em>indicator function</em> for <code>sex == male</code>. In other words, <span class="math inline">\(\mathbb{1}_{\mbox{is male}}(x)\)</span> equals one if the current observation corresponds to a male professor, and 0 if the current observation corresponds to a female professor. This model can be visualized in Figure <a href="#fig:numxcatxplot2">1.5</a>.</p>
<div class="figure"><span id="fig:numxcatxplot2"></span>
<img src="07-multiple-regression_files/figure-html/numxcatxplot2-1.png" alt="Instructor evaluation scores at UT Austin by gender: same slope" width="\textwidth" />
<p class="caption">
Figure 1.5: Instructor evaluation scores at UT Austin by gender: same slope
</p>
</div>
<p>We see that:</p>
<ul>
<li>Females are treated as the baseline for comparison for no other reason than “female” is alphabetically earlier than “male.” The <span class="math inline">\(b_{male} = 0.1906\)</span> is the vertical “bump” that men get in their teaching evaluation scores. Or more precisely, it is the average difference in teaching score
that men get <em>relative to the baseline of women</em>.</li>
<li>Accordingly, the intercepts (which in this case make no sense since no instructor can have an age of 0) are :
<ul>
<li>for women: <span class="math inline">\(b_0\)</span> = 4.484</li>
<li>for men: <span class="math inline">\(b_0 + b_{male}\)</span> = 4.484 + 0.191 = 4.675</li>
</ul></li>
<li>Both men and women have the same slope. In other words, <em>in this model</em> the associated effect of age is the same for men and women. So for every increase of one year in age, there is on average an associated change of <span class="math inline">\(b_{age}\)</span> = -0.009 (a decrease) in teaching score.</li>
</ul>
<p>But wait, why is Figure <a href="#fig:numxcatxplot2">1.5</a> different than Figure <a href="#fig:numxcatxplot1">1.4</a>! What is going on? What we have in the original plot is known as an <em>interaction effect</em> between age and gender. Focusing on fitting a model for each of men and women, we see that the resulting regression lines are different. Thus, <code>gender</code> appears to interact in different ways for men and women with the different values of <code>age</code>.</p>
</div>
<div id="model4interactiontable" class="section level3">
<h3><span class="header-section-number">1.2.3</span> 多元回归：交互模型</h3>
<p>We say a model has an <em>interaction effect</em> if the associated effect of one variable <em>depends on the value of another variable</em>. These types of models usually prove to be tricky to view on first glance because of their complexity. In this case, the effect of <code>age</code> will depend on the value of <code>gender</code>. Put differently, the effect of age on teaching scores will differ for men and for women, as was suggested by the different slopes for men and women in our visual exploratory data analysis in Figure <a href="#fig:numxcatxplot1">1.4</a>.</p>
<p>Let’s fit a regression with an interaction term. Instead of using the <code>+</code> sign in the enumeration of explanatory variables, we use the <code>*</code> sign. Let’s fit this regression and save it in <code>score_model_3</code>, then we get the regression table using the <code>get_regression_table()</code> function as before.</p>
<pre class="sourceCode r"><code class="sourceCode r">score_model_interaction &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">*</span><span class="st"> </span>gender, <span class="dt">data =</span> evals_ch7)
<span class="kw">get_regression_table</span>(score_model_interaction)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-31">Table 1.7: </span>Regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">lower_ci</th>
<th align="right">upper_ci</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">4.883</td>
<td align="right">0.205</td>
<td align="right">23.80</td>
<td align="right">0.000</td>
<td align="right">4.480</td>
<td align="right">5.286</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">-0.018</td>
<td align="right">0.004</td>
<td align="right">-3.92</td>
<td align="right">0.000</td>
<td align="right">-0.026</td>
<td align="right">-0.009</td>
</tr>
<tr class="odd">
<td align="left">gendermale</td>
<td align="right">-0.446</td>
<td align="right">0.265</td>
<td align="right">-1.68</td>
<td align="right">0.094</td>
<td align="right">-0.968</td>
<td align="right">0.076</td>
</tr>
<tr class="even">
<td align="left">age:gendermale</td>
<td align="right">0.014</td>
<td align="right">0.006</td>
<td align="right">2.45</td>
<td align="right">0.015</td>
<td align="right">0.003</td>
<td align="right">0.024</td>
</tr>
</tbody>
</table>
<p>The modeling equation for this scenario is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{y} &amp;= b_0 + b_1 \cdot x_1 + b_2 \cdot x_2 + b_3 \cdot x_1 \cdot x_2\\
\widehat{\mbox{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x) + b_{\mbox{age,male}} \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}(x) \\
\end{align}
\]</span></p>
<p>Oof, that’s a lot of rows in the regression table output and a lot of terms in the model equation. The fourth term being added on the right hand side of the equation corresponds to the <em>interaction term</em>. Let’s simplify things by considering men and women separately. First, recall that <span class="math inline">\(\mathbb{1}_{\mbox{is male}}(x)\)</span> equals 1 if a particular observation (or row in <code>evals_ch7</code>) corresponds to a male instructor. In this case, using the values from the regression table the fitted value of <span class="math inline">\(\widehat{\mbox{score}}\)</span> is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{\mbox{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x) + b_{\mbox{age,male}} \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}(x) \\
&amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot 1 + b_{\mbox{age,male}} \cdot \mbox{age} \cdot 1 \\
&amp;= \left(b_0 + b_{\mbox{male}}\right) + \left(b_{\mbox{age}} +  b_{\mbox{age,male}} \right) \cdot \mbox{age} \\
&amp;= \left(4.883 + -0.446\right) + \left(-0.018 +  0.014 \right) \cdot \mbox{age} \\
&amp;= 4.437 -0.004 \cdot \mbox{age}
\end{align}
\]</span></p>
<p>Second, recall that <span class="math inline">\(\mathbb{1}_{\mbox{is male}}(x)\)</span> equals 0 if a particular observation corresponds to a female instructor. Again, using the values from the regression table the fitted value of <span class="math inline">\(\widehat{\mbox{score}}\)</span> is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{\mbox{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x) + b_{\mbox{age,male}} \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}(x) \\
&amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot 0 + b_{\mbox{age,male}}\mbox{age} \cdot 0 \\
&amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age}\\
&amp;= 4.883 -0.018 \cdot \mbox{age}
\end{align}
\]</span></p>
<p>Let’s summarize these values in a table:</p>
<table>
<caption><span id="tab:unnamed-chunk-32">Table 1.8: </span>Comparison of male and female intercepts and age slopes</caption>
<thead>
<tr class="header">
<th align="left">Gender</th>
<th align="right">Intercept</th>
<th align="right">Slope for age</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Male instructors</td>
<td align="right">4.44</td>
<td align="right">-0.004</td>
</tr>
<tr class="even">
<td align="left">Female instructors</td>
<td align="right">4.88</td>
<td align="right">-0.018</td>
</tr>
</tbody>
</table>
<p>We see that while male instructors have a lower intercept, as they age, they have a less steep associated average decrease in teaching scores: 0.004 teaching score units per year as opposed to -0.018 for women. This is consistent with the different slopes and intercepts of the red and blue regression lines fit in Figure <a href="#fig:numxcatxplot1">1.4</a>. Recall our definition of a model having an interaction effect: when the associated effect of one variable, in this case <code>age</code>, depends on the value of another variable, in this case <code>gender</code>.</p>
<p>But how do we know when it’s appropriate to include an interaction effect? For example, which is the more appropriate model? The regular multiple regression model without an interaction term we saw in Section <a href="#model4table">1.2.2</a> or the multiple regression model with the interaction term we just saw? We’ll revisit this question in Chapter <a href="#inference-for-regression"><strong>??</strong></a> on “inference for regression.”</p>
</div>
<div id="model4points" class="section level3">
<h3><span class="header-section-number">1.2.4</span> 观察值,拟合值,残差</h3>
<p>Now say we want to apply the above calculations for male and female instructors for all 463 instructors in the <code>evals_ch7</code> dataset. As our multiple regression models get more and more complex, computing such values by hand gets more and more tedious. The <code>get_regression_points()</code> function spares us this tedium and returns all fitted values and all residuals. For simplicity, let’s focus only on the fitted interaction model, which is saved in <code>score_model_interaction</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(score_model_interaction)
regression_points</code></pre>
<table>
<caption><span id="tab:model4-points-table">Table 1.9: </span>Regression points (first 5 rows of 463)</caption>
<thead>
<tr class="header">
<th align="right">ID</th>
<th align="right">score</th>
<th align="right">age</th>
<th align="left">gender</th>
<th align="right">score_hat</th>
<th align="right">residual</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">4.7</td>
<td align="right">36</td>
<td align="left">female</td>
<td align="right">4.25</td>
<td align="right">0.448</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">4.1</td>
<td align="right">36</td>
<td align="left">female</td>
<td align="right">4.25</td>
<td align="right">-0.152</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">3.9</td>
<td align="right">36</td>
<td align="left">female</td>
<td align="right">4.25</td>
<td align="right">-0.352</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">4.8</td>
<td align="right">36</td>
<td align="left">female</td>
<td align="right">4.25</td>
<td align="right">0.548</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">4.6</td>
<td align="right">59</td>
<td align="left">male</td>
<td align="right">4.20</td>
<td align="right">0.399</td>
</tr>
</tbody>
</table>
<p>Recall the format of the output:</p>
<ul>
<li><code>score</code> corresponds to <span class="math inline">\(y\)</span> the observed value</li>
<li><code>score_hat</code> corresponds to <span class="math inline">\(\widehat{y} = \widehat{\mbox{score}}\)</span> the fitted value</li>
<li><code>residual</code> corresponds to the residual <span class="math inline">\(y - \widehat{y}\)</span></li>
</ul>
</div>
<div id="model4residuals" class="section level3">
<h3><span class="header-section-number">1.2.5</span> 残差分</h3>
<p>As always, let’s perform a residual analysis first with a histogram, which we can facet by <code>gender</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.25</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Residual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>gender)</code></pre>
<div class="figure"><span id="fig:residual1"></span>
<img src="07-multiple-regression_files/figure-html/residual1-1.png" alt="Interaction model histogram of residuals" width="\textwidth" />
<p class="caption">
Figure 1.6: Interaction model histogram of residuals
</p>
</div>
<p>Second, the residuals as compared to the predictor variables:</p>
<ul>
<li><span class="math inline">\(x_1\)</span>: numerical explanatory/predictor variable of <code>age</code></li>
<li><span class="math inline">\(x_2\)</span>: categorical explanatory/predictor variable of <code>gender</code></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;age&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>gender)</code></pre>
<div class="figure"><span id="fig:residual2"></span>
<img src="07-multiple-regression_files/figure-html/residual2-1.png" alt="Interaction model residuals vs predictor" width="\textwidth" />
<p class="caption">
Figure 1.7: Interaction model residuals vs predictor
</p>
</div>
</div>
</div>
<div id="section-1.3" class="section level2">
<h2><span class="header-section-number">1.3</span> 其他内容</h2>
<div id="correlationcoefficient2" class="section level3">
<h3><span class="header-section-number">1.3.1</span> 更多相关系数的内容</h3>
<p>Recall from Table <a href="#tab:model3-correlation">1.2</a> that we saw the correlation
coefficient between <code>Income</code> in thousands of dollars and credit card <code>Balance</code>
was 0.464. What if in instead we looked at the correlation coefficient between
<code>Income</code> and credit card <code>Balance</code>, but where <code>Income</code> was in dollars and not
thousands of dollars? This can be done by multiplying <code>Income</code> by 1000.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
<span class="kw">data</span>(Credit)
Credit <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Balance, Income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Income =</span> Income <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()</code></pre>
<table>
<caption><span id="tab:cor-credit-2">Table 1.10: </span>Correlation between income (in $) and credit card balance</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Balance</td>
<td align="right">1.000</td>
<td align="right">0.464</td>
</tr>
<tr class="even">
<td>Income</td>
<td align="right">0.464</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<p>We see it is the same! We say that the correlation coefficient is invariant to linear
transformations! In other words,</p>
<ul>
<li>the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> will be the same as</li>
<li>the correlation between <span class="math inline">\(a\times x + b\)</span> and <span class="math inline">\(y\)</span> where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are numerical values (real numbers in mathematical terms).</li>
</ul>
</div>
<div id="simpsonsparadox" class="section level3">
<h3><span class="header-section-number">1.3.2</span> 辛普森的悖论(Simpson’s Paradox)</h3>
<p>Recall in Section <a href="#model3">1.1</a>, we saw the two following seemingly contradictory results when studying the relationship between credit card balance, credit limit, and income. On the one hand, the right hand plot of Figure <a href="#fig:2numxplot1">1.1</a> suggested that credit card balance and income were positively related:</p>
<div class="figure"><span id="fig:unnamed-chunk-35"></span>
<img src="07-multiple-regression_files/figure-html/unnamed-chunk-35-1.png" alt="Relationship between credit card balance and credit limit/income" width="\textwidth" />
<p class="caption">
Figure 1.8: Relationship between credit card balance and credit limit/income
</p>
</div>
<p>On the other hand, the multiple regression in Table <a href="#tab:model3-table-output">1.3</a>, suggested that when modeling credit card balance as a function of both credit limit and income at the same time, credit limit has a negative relationship with balance, as evidenced by the slope of -7.66. How can this be?</p>
<p>First, let’s dive a little deeper into the explanatory variable <code>Limit</code>. Figure <a href="#fig:credit-limit-quartiles">1.9</a> shows a histogram of all 400 values of <code>Limit</code>, along with vertical red lines that cut up the data into quartiles, meaning:</p>
<ol style="list-style-type: decimal">
<li>25% of credit limits were between $0 and $3088. Let’s call this the “low” credit limit bracket.</li>
<li>25% of credit limits were between $3088 and $4622. Let’s call this the “medium-low” credit limit bracket.</li>
<li>25% of credit limits were between $4622 and $5873. Let’s call this the “medium-high” credit limit bracket.</li>
<li>25% of credit limits were over $5873. Let’s call this the “high” credit limit bracket.</li>
</ol>
<div class="figure"><span id="fig:credit-limit-quartiles"></span>
<img src="07-multiple-regression_files/figure-html/credit-limit-quartiles-1.png" alt="Histogram of credit limits and quartiles" width="\textwidth" />
<p class="caption">
Figure 1.9: Histogram of credit limits and quartiles
</p>
</div>
<p>Let’s now display</p>
<ol style="list-style-type: decimal">
<li>The scatterplot showing the relationship between credit card balance and limit (the right-hand plot of Figure <a href="#fig:2numxplot1">1.1</a>).</li>
<li>The scatterplot showing the relationship between credit card balance and limit now with a color aesthetic added corresponding to the credit limit bracket.</li>
</ol>
<div class="figure"><span id="fig:2numxplot4"></span>
<img src="07-multiple-regression_files/figure-html/2numxplot4-1.png" alt="Relationship between credit card balance and income for different credit limit brackets" width="\textwidth" />
<p class="caption">
Figure 1.10: Relationship between credit card balance and income for different credit limit brackets
</p>
</div>
<p>In the right-hand plot, the</p>
<ul>
<li>Red points (bottom-left) correspond to the low credit limit bracket.</li>
<li>Green points correspond to the medium-low credit limit bracket.</li>
<li>Blue points correspond to the medium-high credit limit bracket.</li>
<li>Purple points (top-right) correspond to the high credit limit bracket.</li>
</ul>
<p>The left-hand plot focuses of the relationship between balance and income in aggregate, but the right-hand plot focuses on the relationship between balance and income <em>broken down by credit limit bracket</em>. Whereas in aggregate there is an overall positive relationship, when broken down we now see that for the low (red points), medium-low (green points), and medium-high (blue points) income bracket groups, the strong positive relationship between credit card balance and income disappears! Only for the high bracket does the relationship stay somewhat positive. In this example, credit limit is a <em>confounding variable</em> for credit card balance and income.</p>
<!--
Alternatively, we could also have used facets, where each facet has roughly 25% of people based
on the credit limit bracket. However, IMO the above plot is easier to read.

<div class="figure">
<img src="07-multiple-regression_files/figure-html/2numxplot5-1.png" alt="Relationship between credit card balance and income for different credit limit brackets" width="\textwidth" />
<p class="caption">(\#fig:2numxplot5)Relationship between credit card balance and income for different credit limit brackets</p>
</div>
-->
</div>
</div>
<div id="section-1.4" class="section level2">
<h2><span class="header-section-number">1.4</span> 结论</h2>
<div id="section-1.4.1" class="section level3">
<h3><span class="header-section-number">1.4.1</span> 本书后面的内容?</h3>
<p>Congratulations! We’re ready to proceed to the third portion of this book: “statistical inference” using a new package called <code>infer</code>. Once we’ve covered Chapters <a href="#sampling"><strong>??</strong></a> on sampling, <a href="#confidence-intervals"><strong>??</strong></a> on confidence intervals, and <a href="#hypothesis-testing"><strong>??</strong></a> on hypothesis testing, we’ll come back to the models we’ve seen in “data modeling” in Chapter <a href="#inference-for-regression"><strong>??</strong></a> on inference for regression. As we said at the end of Chapter <a href="#regression"><strong>??</strong></a>, we’ll see why we’ve been conducting the residual analyses from Subsections <a href="#model3residuals">1.1.4</a> and <a href="#model4residuals">1.2.5</a>. We are actually verifying some very important assumptions that must be met for the <code>std_error</code> (standard error), <code>p_value</code>, <code>conf_low</code> and <code>conf_high</code> (the end-points of the confidence intervals) columns in our regression tables to have valid interpretation.</p>
<p>Up next:</p>
<center>
<img src="images/flowcharts/flowchart/flowchart.006.png" title="ModernDive flowchart" width="800"/>
</center>
</div>
<div id="r" class="section level3">
<h3><span class="header-section-number">1.4.2</span> R代码</h3>
<p>本章节《基本回归分析》的所有代码:
<a href="https://moderndive.com/scripts/07-multiple-regression.R">here</a>.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/moderndive/moderndive_book/edit/master/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
